import streamlit as st
import pandas as pd
import folium
from streamlit_folium import st_folium
import json
import io
import os
from shapely.geometry import Point, shape
from io import BytesIO

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡ ---
st.set_page_config(page_title="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø®Ø³Ø§Ø±Øª Ù…Ø¯Ø§Ø±Ø³", layout="wide")
st.title("Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø®Ø³Ø§Ø±Øª Ù…Ø¯Ø§Ø±Ø³ Ø¯Ø± Ø¨Ø­Ø±Ø§Ù†")

# --- Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ Ùˆ Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§ ---
# Ù„ÛŒØ³Øª Ù…Ù‚Ø§Ø·Ø¹ ØªØ­ØµÛŒÙ„ÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± ÙÛŒÙ„ØªØ±Ù‡Ø§ Ùˆ Ú¯Ø²Ø§Ø±Ø´
EDUCATION_LEVELS = ["Ø§Ø¨ØªØ¯Ø§ÛŒÛŒ", "Ù…ØªÙˆØ³Ø·Ù‡ Ø§ÙˆÙ„", "Ù…ØªÙˆØ³Ø·Ù‡ Ø¯ÙˆÙ…", "ÙÙ†ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"]

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---

# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ú©Ø§Ù†ÛŒ: Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù†Ù‚Ø·Ù‡ (Ù…Ø¯Ø±Ø³Ù‡) Ø¯Ø§Ø®Ù„ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ† (Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨) Ø§Ø³Øª.
@st.cache_data
def check_for_overlap(df_schools, damage_polygons):
    """
    Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ø¯Ø§Ù… Ù…Ø¯Ø§Ø±Ø³ (Ù†Ù‚Ø§Ø·) Ø¯Ø± Ø¯Ø§Ø®Ù„ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯.
    Ø§Ø² shapely Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù‡Ù†Ø¯Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ØªØ¹Ø±ÛŒÙ Ø³ØªÙˆÙ† damage_status Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡
    df_schools['damage_status'] = 'Ø³Ø§Ù„Ù…' 

    # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†ÛŒ ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ù‡Ù…Ù‡ Ù…Ø¯Ø§Ø±Ø³ Ø³Ø§Ù„Ù… Ù‡Ø³ØªÙ†Ø¯.
    if not damage_polygons:
        return df_schools
    
    # Ø³Ø§Ø®ØªÙ† Ø§Ø´ÛŒØ§Ø¡ Point Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ø§Ø±Ø³
    schools_points = [
        Point(row['longitude'], row['latitude'])
        for index, row in df_schools.iterrows()
    ]
    
    # ØªØ¹Ø±ÛŒÙ Ø³ØªÙˆÙ† Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø®Ø³Ø§Ø±Øª
    is_damaged = [False] * len(df_schools)

    # Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø¯Ø±Ø³Ù‡ Ú©Ù‡ Ø¢ÛŒØ§ Ø¯Ø§Ø®Ù„ Ù‡Ø± ÛŒÚ© Ø§Ø² Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ Ù‡Ø³Øª ÛŒØ§ Ø®ÛŒØ±
    for i, school_point in enumerate(schools_points):
        for damage_polygon in damage_polygons:
            if school_point.within(damage_polygon):
                is_damaged[i] = True
                break  # Ø§Ú¯Ø± Ø¯Ø± ÛŒÚ© Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨ Ø¨ÙˆØ¯ØŒ Ø¯ÛŒÚ¯Ø± Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ù‚ÛŒÙ‡ Ù†ÛŒØ³Øª

    # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³ØªÙˆÙ† damage_status Ø¯Ø± DataFrame
    df_schools['damage_status'] = ['Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡' if damaged else 'Ø³Ø§Ù„Ù…' for damaged in is_damaged]

    return df_schools

# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ GeoJSON Ø¨Ù‡ Ù„ÛŒØ³Øª Ø¢Ø¨Ø¬Ú©Øªâ€ŒÙ‡Ø§ÛŒ Shapely Polygon
def extract_shapely_polygons(geojson_data):
    """
    ÙØ§ÛŒÙ„ GeoJSON ÛŒØ§ JSON ØªØ±Ø³ÛŒÙ…ÛŒ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ Ùˆ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ù„ÛŒØ³Øª Ø§Ø´ÛŒØ§Ø¡ Shapely Polygon ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    polygons = []
    
    # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ø§Ø² Draw Tool Ø¨Ø§Ø´Ø¯
    if isinstance(geojson_data, dict) and 'all_drawings' in geojson_data:
        features = geojson_data['all_drawings']
    # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ ÛŒÚ© ÙØ§ÛŒÙ„ GeoJSON Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
    elif isinstance(geojson_data, dict) and 'features' in geojson_data:
        features = geojson_data['features']
    else:
        return []

    for feature in features:
        if feature['geometry']['type'] in ['Polygon', 'MultiPolygon']:
            try:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² shapely.geometry.shape Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ø´ÛŒØ¡ Ù‡Ù†Ø¯Ø³ÛŒ
                geom = shape(feature['geometry'])
                if geom.geom_type == 'Polygon':
                    polygons.append(geom)
                elif geom.geom_type == 'MultiPolygon':
                    polygons.extend(list(geom.geoms))
            except Exception as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ GeoJSON: {e}")
                
    return polygons

# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ CSV Ù‚Ø§Ø¨Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯
def to_excel(df):
    """ØªØ¨Ø¯ÛŒÙ„ DataFrame Ø¨Ù‡ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ (BytesIO)"""
    output = BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    df.to_excel(writer, index=False, sheet_name='Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡')
    writer.close()
    processed_data = output.getvalue()
    return processed_data

# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ ---
def load_data():
    """ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„/CSV Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ø§Ø±Ø³."""
    # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ø­Ø§Ù„Øª Ø³Ø´Ù† Ø°Ø®ÛŒØ±Ù‡ Ù†Ø´Ø¯Ù‡ØŒ Ø§Ø² ÛŒÚ© ÙØ§ÛŒÙ„ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯ (Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¨Ø¯ÙˆÙ† Ø¢Ù¾Ù„ÙˆØ¯)
    if 'school_data' not in st.session_state:
        st.info("Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Excel/CSV Ø­Ø§ÙˆÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ø§Ø±Ø³ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")
        
        # Ø³Ø§Ø®Øª ÛŒÚ© DataFrame Ù†Ù…ÙˆÙ†Ù‡ (Mock Data) Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø§ÙˆÙ„ÛŒÙ‡
        mock_data = {
            'school_code': [1001, 1002, 1003, 1004, 1005],
            'name': ['Ù…Ø¯Ø±Ø³Ù‡ Ø§Ù„Ù', 'Ù…Ø¯Ø±Ø³Ù‡ Ø¨', 'Ù…Ø¯Ø±Ø³Ù‡ Ø¬', 'Ù…Ø¯Ø±Ø³Ù‡ Ø¯', 'Ù…Ø¯Ø±Ø³Ù‡ Ù‡'],
            'latitude': [35.70, 35.71, 35.75, 35.80, 35.78],
            'longitude': [51.40, 51.45, 51.35, 51.50, 51.42],
            'level': ["Ø§Ø¨ØªØ¯Ø§ÛŒÛŒ", "Ù…ØªÙˆØ³Ø·Ù‡ Ø§ÙˆÙ„", "Ù…ØªÙˆØ³Ø·Ù‡ Ø¯ÙˆÙ…", "Ø§Ø¨ØªØ¯Ø§ÛŒÛŒ", "Ù…ØªÙˆØ³Ø·Ù‡ Ø§ÙˆÙ„"],
            'type': ["Ù¾Ø³Ø±Ø§Ù†Ù‡", "Ø¯Ø®ØªØ±Ø§Ù†Ù‡", "Ù¾Ø³Ø±Ø§Ù†Ù‡", "Ø¯Ø®ØªØ±Ø§Ù†Ù‡", "Ù¾Ø³Ø±Ø§Ù†Ù‡"],
            'students_boys': [150, 0, 180, 0, 120],
            'students_girls': [0, 160, 0, 170, 0],
            'teachers': [12, 10, 15, 11, 8],
        }
        st.session_state['school_data'] = pd.DataFrame(mock_data)

    return st.session_state['school_data']

# --- UI Ùˆ ÙÛŒÙ„ØªØ±Ù‡Ø§ ---

def setup_sidebar(df):
    """ØªÙ†Ø¸ÛŒÙ… ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ."""
    st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ ÙÛŒÙ„ØªØ±Ù‡Ø§")

    # Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
    uploaded_file = st.sidebar.file_uploader(
        "Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ø§Ø±Ø³ (Excel/CSV)", 
        type=['csv', 'xlsx'], 
        key='file_uploader'
    )
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            elif uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
                
            st.session_state['school_data'] = df
            st.sidebar.success("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯.")
        except Exception as e:
            st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: {e}")
            
    # ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
    st.sidebar.markdown("---")
    selected_levels = st.sidebar.multiselect(
        "ÙÛŒÙ„ØªØ± Ù…Ù‚Ø·Ø¹ ØªØ­ØµÛŒÙ„ÛŒ",
        options=df['level'].unique().tolist() if 'level' in df.columns else EDUCATION_LEVELS,
        default=df['level'].unique().tolist() if 'level' in df.columns else EDUCATION_LEVELS
    )

    selected_types = st.sidebar.multiselect(
        "ÙÛŒÙ„ØªØ± Ø¬Ù†Ø³ÛŒØª",
        options=df['type'].unique().tolist() if 'type' in df.columns else ["Ù¾Ø³Ø±Ø§Ù†Ù‡", "Ø¯Ø®ØªØ±Ø§Ù†Ù‡", "Ù…Ø®ØªÙ„Ø·"],
        default=df['type'].unique().tolist() if 'type' in df.columns else ["Ù¾Ø³Ø±Ø§Ù†Ù‡", "Ø¯Ø®ØªØ±Ø§Ù†Ù‡", "Ù…Ø®ØªÙ„Ø·"]
    )
    
    st.session_state['selected_levels'] = selected_levels
    st.session_state['selected_types'] = selected_types

    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† DataFrame
    if 'level' in df.columns and 'type' in df.columns:
        filtered_df = df[
            (df['level'].isin(selected_levels)) & 
            (df['type'].isin(selected_types))
        ].copy()
    else:
        filtered_df = df.copy() # Ù†Ù…Ø§ÛŒØ´ Ù‡Ù…Ù‡ Ø§Ú¯Ø± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ø¯

    return filtered_df

# --- Ù…Ù†Ø·Ù‚ Ø§ØµÙ„ÛŒ Ù†Ù‚Ø´Ù‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ ---

def main_map_and_analysis(filtered_df):
    """
    Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ØŒ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ØªØ±Ø³ÛŒÙ… Ùˆ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ú©Ø§Ù†ÛŒ.
    """
    
    if filtered_df.empty:
        st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        return

    # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ø®ØªØµØ§Øª Ø¨Ø±Ø§ÛŒ Ù…Ø±Ú©Ø² Ù†Ù‚Ø´Ù‡ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§)
    if 'latitude' in filtered_df.columns and 'longitude' in filtered_df.columns:
        center_lat = filtered_df['latitude'].mean()
        center_lon = filtered_df['longitude'].mean()
    else:
        st.error("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'latitude' Ùˆ 'longitude' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ø§Ø±Ø³ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯.")
        # Ù…Ø®ØªØµØ§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ (ØªÙ‡Ø±Ø§Ù†)
        center_lat = 35.70
        center_lon = 51.40


    # --- Ø³Ø§Ø®Øª Ù†Ù‚Ø´Ù‡ Folium ---
    m = folium.Map(location=[center_lat, center_lon], zoom_start=11)

    # Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ Draw Ø¨Ø±Ø§ÛŒ ØªØ±Ø³ÛŒÙ… Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨
    from folium.plugins import Draw
    draw = Draw(
        export=True, 
        filename='damage_area.geojson',
        position='topleft', 
        draw_options={
            'polygon': {'shapeOptions': {'color': '#FF0000', 'fillColor': '#FF0000', 'fillOpacity': 0.3}},
            'marker': False,
            'circlemarker': False,
            'polyline': False,
            'rectangle': False,
            'circle': False
        },
        edit_options={'edit': True, 'remove': True}
    )
    draw.add_to(m)

    # Ø§ÙØ²ÙˆØ¯Ù† Ù†Ù‚Ø§Ø· Ù…Ø¯Ø§Ø±Ø³ Ø¨Ù‡ Ù†Ù‚Ø´Ù‡
    for index, row in filtered_df.iterrows():
        popup_html = f"""
        <b>Ù†Ø§Ù…:</b> {row.get('name', 'N/A')}<br>
        <b>Ú©Ø¯:</b> {row.get('school_code', 'N/A')}<br>
        <b>Ù…Ù‚Ø·Ø¹:</b> {row.get('level', 'N/A')}<br>
        <b>Ø¬Ù†Ø³ÛŒØª:</b> {row.get('type', 'N/A')}<br>
        <b>Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†:</b> {row.get('students_boys', 0) + row.get('students_girls', 0)}
        """
        
        folium.CircleMarker(
            location=[row['latitude'], row['longitude']],
            radius=5,
            color='blue',
            fill=True,
            fill_color='blue',
            fill_opacity=0.7,
            popup=popup_html
        ).add_to(m)

    st.subheader("Ù†Ù‚Ø´Ù‡ ØªØ¹Ø§Ù…Ù„ÛŒ Ù…Ø¯Ø§Ø±Ø³ Ùˆ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨")
    
    # --- Ø§Ø¨Ø²Ø§Ø± Ø¢Ù¾Ù„ÙˆØ¯ GeoJSON Ø¯Ø± Ø³ØªÙˆÙ† Ú©Ù†Ø§Ø±ÛŒ ---
    with st.sidebar.expander("Ø¢Ù¾Ù„ÙˆØ¯ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨ (GeoJSON)"):
        geojson_upload = st.file_uploader(
            "ÙØ§ÛŒÙ„ GeoJSON Ø­Ø§ÙˆÛŒ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¢Ø³ÛŒØ¨ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯",
            type=['geojson']
        )
        
        if geojson_upload:
            try:
                geojson_data = json.load(geojson_upload)
                st.session_state['damage_geojson'] = geojson_data
                st.sidebar.success("ÙØ§ÛŒÙ„ GeoJSON Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
            except Exception as e:
                st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† GeoJSON: {e}")

    # Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Streamlit-Folium Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø³ÛŒÙ… Ø´Ø¯Ù‡
    map_result = st_folium(
        m, 
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 'stretch' Ø¨Ù‡ Ø¬Ø§ÛŒ use_container_width=True Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ù‡Ø´Ø¯Ø§Ø± Ù…Ù†Ø³ÙˆØ® Ø´Ø¯Ù†
        width="stretch", 
        height=500, 
        key="school_map"
    )

    # --- ØªØ­Ù„ÛŒÙ„ Ù…Ú©Ø§Ù†ÛŒ ---

    # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø³ÛŒÙ… Ø´Ø¯Ù‡
    drawn_polygons_geojson = map_result.get("all_drawings")
    
    # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)
    uploaded_geojson = st.session_state.get('damage_geojson', None)

    # ØªØ±Ú©ÛŒØ¨ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Shapely Polygons
    all_polygons_shapely = []
    
    if drawn_polygons_geojson:
        all_polygons_shapely.extend(extract_shapely_polygons(drawn_polygons_geojson))
        
    if uploaded_geojson:
        # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù‡Ù… ØªØ±Ø³ÛŒÙ… Ú©Ø±Ø¯Ù‡ Ùˆ Ù‡Ù… Ø¢Ù¾Ù„ÙˆØ¯ØŒ ÙÙ‚Ø· Ø§Ø² ØªØ±Ø³ÛŒÙ…ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ù…Ú¯Ø± Ø§ÛŒÙ†Ú©Ù‡ ÙˆØ§Ø¶Ø­ Ø¨Ø§Ø´Ø¯
        # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ØŒ Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ù„ÛŒØ³Øª Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        all_polygons_shapely.extend(extract_shapely_polygons(uploaded_geojson))
        
    if all_polygons_shapely:
        # Ø§Ú¯Ø± Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªØŒ ØªØ­Ù„ÛŒÙ„ Ù…Ú©Ø§Ù†ÛŒ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯
        df_analyzed = check_for_overlap(filtered_df, all_polygons_shapely)
        
        # Ù†Ù…Ø§ÛŒØ´ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡
        for polygon in all_polygons_shapely:
             # ØªØ¨Ø¯ÛŒÙ„ shapely polygon Ø¨Ù‡ GeoJSON Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Folium
            geojson_to_add = folium.GeoJson(polygon.wkt, style_function=lambda x: {
                'fillColor': '#FF0000', 
                'color': '#FF0000', 
                'weight': 3, 
                'fillOpacity': 0.3
            })
            geojson_to_add.add_to(m)
            
        # Ø¨Ø§ÛŒØ¯ Ù†Ù‚Ø´Ù‡ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù†Ù…Ø§ÛŒØ´ Ø¯Ù‡ÛŒÙ… ØªØ§ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ Ø¸Ø§Ù‡Ø± Ø´ÙˆÙ†Ø¯
        st.subheader("Ù†Ù‚Ø´Ù‡ Ù†Ù‡Ø§ÛŒÛŒ (Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨)")
        st_folium(m, width="stretch", height=500, key="final_map")
        
        return df_analyzed
    
    else:
        st.info("Ù„Ø·ÙØ§Ù‹ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ Ø±Ø§ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ ØªØ±Ø³ÛŒÙ… Ú©Ù†ÛŒØ¯ ÛŒØ§ ÙØ§ÛŒÙ„ GeoJSON Ø¢Ù† Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ù…Ø§ÛŒÛŒØ¯.")
        # Ø§Ú¯Ø± Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ ÙˆØ¶Ø¹ÛŒØª Ø®Ø³Ø§Ø±Øª Ø±Ø§ Ø¨Ù‡ Ø­Ø§Ù„Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ (Ø³Ø§Ù„Ù…) Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯
        filtered_df['damage_status'] = 'Ø³Ø§Ù„Ù…'
        return filtered_df
    
# --- Ø¨Ø®Ø´ Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ ---

def display_results(df_analyzed):
    """
    Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø± Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡.
    """
    
    st.markdown("---")
    st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ú¯Ø²Ø§Ø±Ø´ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø®Ø³Ø§Ø±Øª")

    df_damaged = df_analyzed[df_analyzed['damage_status'] == 'Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡']
    total_damaged_schools = len(df_damaged)

    # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            label="ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø¯Ø§Ø±Ø³ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡", 
            value=f"{len(df_analyzed)} Ù…Ø¯Ø±Ø³Ù‡"
        )
    with col2:
        st.metric(
            label="Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ (Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø®Ø³Ø§Ø±Øª)", 
            value=f"{total_damaged_schools} Ù…Ø¯Ø±Ø³Ù‡",
            delta_color="inverse"
        )
    with col3:
        total_students_damaged = df_damaged['students_boys'].sum() + df_damaged['students_girls'].sum()
        st.metric(
            label="Ú©Ù„ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† ØªØ­Øª ØªØ£Ø«ÛŒØ±", 
            value=f"{total_students_damaged} Ù†ÙØ±"
        )

    if total_damaged_schools > 0:
        st.markdown("#### Ø¢Ù…Ø§Ø± ØªÙÚ©ÛŒÚ©ÛŒ Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡:")
        
        # Ø¢Ù…Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø·Ø¹
        damage_by_level = df_damaged.groupby('level')['school_code'].count().reset_index(name='ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ø§Ø±Ø³')
        damage_by_level = damage_by_level.rename(columns={'level': 'Ù…Ù‚Ø·Ø¹ ØªØ­ØµÛŒÙ„ÛŒ'})
        
        # Ø¢Ù…Ø§Ø± Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†
        students_by_type = pd.DataFrame({
            'Ø¬Ù†Ø³ÛŒØª': ['Ù¾Ø³Ø±', 'Ø¯Ø®ØªØ±'],
            'ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†': [df_damaged['students_boys'].sum(), df_damaged['students_girls'].sum()]
        })

        # Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø¯Ùˆ Ø³ØªÙˆÙ†
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("##### ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø·Ø¹")
            st.dataframe(damage_by_level, hide_index=True, use_container_width=True)

        with c2:
            st.markdown("##### ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¬Ù†Ø³ÛŒØª")
            st.dataframe(students_by_type, hide_index=True, use_container_width=True)

        # Ø¬Ø¯ÙˆÙ„ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡
        st.markdown("#### Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„ Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡")
        st.dataframe(
            df_damaged[['name', 'level', 'type', 'students_boys', 'students_girls', 'teachers', 'latitude', 'longitude']],
            hide_index=True,
            use_container_width=True
        )

        # Ø¯Ú©Ù…Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´
        df_export = df_damaged.rename(columns={
            'name': 'Ù†Ø§Ù… Ù…Ø¯Ø±Ø³Ù‡', 
            'level': 'Ù…Ù‚Ø·Ø¹',
            'type': 'Ù†ÙˆØ¹ (Ø¬Ù†Ø³ÛŒØª)',
            'students_boys': 'Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ù¾Ø³Ø±',
            'students_girls': 'Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ø¯Ø®ØªØ±',
            'teachers': 'ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¹Ù„Ù…ÛŒÙ†'
        })
        
        # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
        excel_data = to_excel(df_export)
        
        st.download_button(
            label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ (Excel)",
            data=excel_data,
            file_name='schools_damage_report.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        
    else:
        st.success("ğŸ‰ Ù‡ÛŒÚ† Ù…Ø¯Ø±Ø³Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ Ù‚Ø±Ø§Ø± Ù†Ø¯Ø§Ø±Ø¯. (Ø·Ø¨Ù‚ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ)")

# --- Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ ---

if __name__ == "__main__":
    
    # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡
    df_schools = load_data()
    
    # 2. ØªÙ†Ø¸ÛŒÙ… ÙÛŒÙ„ØªØ±Ù‡Ø§ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    df_filtered = setup_sidebar(df_schools)
    
    # 3. Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ØŒ Ø¯Ø±ÛŒØ§ÙØª ÙˆØ±ÙˆØ¯ÛŒ Ø¢Ø³ÛŒØ¨ Ùˆ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
    df_analyzed_with_damage = main_map_and_analysis(df_filtered)
    
    # 4. Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
    if df_analyzed_with_damage is not None:
        display_results(df_analyzed_with_damage)
