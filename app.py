import streamlit as st
import pandas as pd
import folium
from streamlit_folium import st_folium
from shapely.geometry import Polygon, Point, shape
from shapely.ops import unary_union
import requests
import os
import json
import io
import numpy as np

# --- 0. Initialization and Setup ---

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡
st.set_page_config(page_title="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø®Ø³Ø§Ø±Øª Ù…Ø¯Ø§Ø±Ø³", layout="wide")
st.title("Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø®Ø³Ø§Ø±Øª Ù…Ø¯Ø§Ø±Ø³ Ø¯Ø± Ø¨Ø­Ø±Ø§Ù†")

# ØªØ¹Ø±ÛŒÙ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª (Session State) Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª ÙˆØ¶Ø¹ÛŒØª Ù†Ù‚Ø´Ù‡
if 'initial_map_location' not in st.session_state:
    # ØªØ¹ÛŒÛŒÙ† Ù…Ø±Ú©Ø² Ø§ÛŒØ±Ø§Ù† Ùˆ Ø²ÙˆÙ… Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ Ú©Ø´ÙˆØ± Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù†Ù…Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    st.session_state.initial_map_location = [32.5, 53.0]  # Ù…Ø±Ú©Ø² ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø§ÛŒØ±Ø§Ù†
    st.session_state.initial_map_zoom = 5 # Ø²ÙˆÙ… Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ Ú©Ø´ÙˆØ±
if 'uploaded_geojson_data' not in st.session_state:
    st.session_state.uploaded_geojson_data = None
if 'reset_trigger' not in st.session_state:
    st.session_state.reset_trigger = 0

# --- Û±. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ø§Ø±Ø³ ---

# Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© ÙØ§ÛŒÙ„ dummy Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ (Ø§Ú¯Ø± ÙØ§ÛŒÙ„ schools.csv ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª)
if not os.path.exists("schools.csv"):
    try:
        # Ù…Ø®ØªØµØ§Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø²Ø¯ÛŒÚ© Ú¯Ù„Ø³ØªØ§Ù† 
        data = {
            'Ú©Ø¯_Ù…Ø¯Ø±Ø³Ù‡': [100013, 100014, 100015, 100016, 100017, 100018, 100019, 100020, 100021, 100022],
            'Ù†Ø§Ù…_Ù…Ø¯Ø±Ø³Ù‡': ['Ø¯Ø¨Ø³ØªØ§Ù† Ø´Ù‡Ø¯Ø§ÛŒ Ú¯Ù…Ù†Ø§Ù…', 'Ù…ØªÙˆØ³Ø·Ù‡ Ø§Ù†Ø¯ÛŒØ´Ù‡', 'ÙÙ†ÛŒ Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ', 'Ø¯Ø¨Ø³ØªØ§Ù† Ø¢Ø²Ø§Ø¯ÛŒ', 'Ù…ØªÙˆØ³Ø·Ù‡ ÙØ±Ø¯ÙˆØ³ÛŒ', 'Ù¾ÛŒØ´â€ŒØ¯Ø¨Ø³ØªØ§Ù†ÛŒ Ø´Ú©ÙˆÙÙ‡', 'Ù…Ø±Ú©Ø² Ù…Ø´Ø§ÙˆØ±Ø§Ù† Û±', 'Ø¯Ø¨Ø³ØªØ§Ù† ÙØ¬Ø±', 'Ù…ØªÙˆØ³Ø·Ù‡ Ø§Ù„Ø²Ù‡Ø±Ø§', 'Ø¯Ø¨Ø³ØªØ§Ù† Ù‡Ø¯Ù'],
            'Ù†Ø§Ù…_Ù…Ø¯ÛŒØ±': ['Ù….Ø±Ø­ÛŒÙ…ÛŒ', 'Ù†.ØµØ§Ø¯Ù‚ÛŒ', 'Ø¬.Ù…Ø±Ø§Ø¯ÛŒ', 'Ù.Ù†Ø¸Ø±ÛŒ', 'Ø¹.Ø­ÛŒØ¯Ø±ÛŒ', 'Ø².Ù…Ø±Ø§Ø¯Ø®Ø§Ù†ÛŒ', 'Ø§.Ø§Ø³Ø¯ÛŒ', 'Ù….Ø¬Ø¹ÙØ±ÛŒ', 'Ø³.Ú©Ø±ÛŒÙ…ÛŒ', 'Ø¬.Ù†ÙˆØ±ÛŒ'],
            'Ù…Ù‚Ø·Ø¹_ØªØ­ØµÛŒÙ„ÛŒ': ['Ø¯Ø¨Ø³ØªØ§Ù† Ø¯ÙˆØ±Ù‡ Ø¯ÙˆÙ…', 'Ù…ØªÙˆØ³Ø·Ù‡ Ø§ÙˆÙ„', 'ÙÙ†ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ', 'Ø¯Ø¨Ø³ØªØ§Ù† Ø¯ÙˆØ±Ù‡ Ø§ÙˆÙ„', 'Ù…ØªÙˆØ³Ø·Ù‡ Ø¯ÙˆÙ…', 'Ù¾ÛŒØ´ Ø¯Ø¨Ø³ØªØ§Ù†ÛŒ', 'Ù…Ø±Ø§Ú©Ø² Ù…Ø´Ø§ÙˆØ±Ù‡', 'Ø¯Ø¨Ø³ØªØ§Ù† Ø¯ÙˆØ±Ù‡ Ø¯ÙˆÙ…', 'Ù…ØªÙˆØ³Ø·Ù‡ Ø¯ÙˆÙ…', 'Ø¯Ø¨Ø³ØªØ§Ù† Ø¯ÙˆØ±Ù‡ Ø§ÙˆÙ„'],
            'ØªØ¹Ø¯Ø§Ø¯_Ø¯Ø§Ù†Ø´_Ø¢Ù…ÙˆØ²': [415, 490, 280, 350, 520, 150, 0, 390, 470, 330],
            'ØªØ¹Ø¯Ø§Ø¯_Ù…Ø¹Ù„Ù…': [29, 31, 30, 24, 34, 12, 18, 26, 30, 23],
            'Ø¬Ù†Ø³ÛŒØª': ['Ù…Ø®ØªÙ„Ø·', 'Ù¾Ø³Ø±Ø§Ù†Ù‡', 'Ù…Ø®ØªÙ„Ø·', 'Ø¯Ø®ØªØ±Ø§Ù†Ù‡', 'Ù¾Ø³Ø±Ø§Ù†Ù‡', 'Ø¯Ø®ØªØ±Ø§Ù†Ù‡', 'Ù…Ø®ØªÙ„Ø·', 'Ù¾Ø³Ø±Ø§Ù†Ù‡', 'Ø¯Ø®ØªØ±Ø§Ù†Ù‡', 'Ù…Ø®ØªÙ„Ø·'],
            'Ø¹Ø±Ø¶_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ': [37.3321, 37.3105, 37.2889, 37.3450, 37.2995, 37.3012, 37.3208, 37.3155, 37.2770, 37.3050],
            'Ø·ÙˆÙ„_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ': [54.5103, 54.4552, 54.5408, 54.4901, 54.4253, 54.5005, 54.4852, 54.5303, 54.4601, 54.4050]
        }
        dummy_df = pd.DataFrame(data)
        dummy_df.to_csv("schools.csv", index=False, encoding="utf-8-sig")
        st.warning("ÙØ§ÛŒÙ„ `schools.csv` Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. ÛŒÚ© ÙØ§ÛŒÙ„ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ Ø¨Ø§ Û±Û° Ù…Ø¯Ø±Ø³Ù‡ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
    except Exception as e:
        st.error(f"ÙØ§ÛŒÙ„ `schools.csv` Ø¯Ø± Ø±ÛŒØ´Ù‡ Ø±ÛŒÙ¾Ø§Ø²ÛŒØªÙˆØ±ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ Ùˆ Ø³Ø§Ø®Øª ÙØ§ÛŒÙ„ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ Ù‡Ù… Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯: {e}")
        st.stop()


@st.cache_data
def load_data():
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ú©Ø´ÛŒÙ†Ú¯."""
    try:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² encoding="utf-8-sig" Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Excel
        df = pd.read_csv("schools.csv", encoding="utf-8-sig")
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¹Ø¯Ø¯ Ùˆ Ù¾Ø± Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù„ÛŒ Ø¨Ø§ 0
        df['Ø¹Ø±Ø¶_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø·ÙˆÙ„_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['ØªØ¹Ø¯Ø§Ø¯_Ø¯Ø§Ù†Ø´_Ø¢Ù…ÙˆØ²'] = pd.to_numeric(df['ØªØ¹Ø¯Ø§Ø¯_Ø¯Ø§Ù†Ø´_Ø¢Ù…ÙˆØ²'], errors='coerce').fillna(0).astype(int)
        df['ØªØ¹Ø¯Ø§Ø¯_Ù…Ø¹Ù„Ù…'] = pd.to_numeric(df['ØªØ¹Ø¯Ø§Ø¯_Ù…Ø¹Ù„Ù…'], errors='coerce').fillna(0).astype(int)
        
        # Ø­Ø°Ù Ø³Ø·Ø±Ù‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù…Ø®ØªØµØ§Øª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ù…Ø¹ØªØ¨Ø±
        df = df.dropna(subset=['Ø¹Ø±Ø¶_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø·ÙˆÙ„_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
        
        # --- ØªØ§Ø¨Ø¹ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù‚Ø§Ø·Ø¹ Ø¨Ø±Ø§ÛŒ Ø±Ù†Ú¯ Ø¨Ù†Ø¯ÛŒ ---
        def categorize_grade(grade):
            grade = str(grade)
            if 'Ø¯Ø¨Ø³ØªØ§Ù†' in grade or 'Ù¾ÛŒØ´ Ø¯Ø¨Ø³ØªØ§Ù†ÛŒ' in grade:
                return 'Ø§Ø¨ØªØ¯Ø§ÛŒÛŒ/Ø¯Ø¨Ø³ØªØ§Ù†'
            elif 'Ù…ØªÙˆØ³Ø·Ù‡' in grade:
                return 'Ù…ØªÙˆØ³Ø·Ù‡'
            elif 'ÙÙ†ÛŒ' in grade or 'Ú©Ø§Ø± Ùˆ Ø¯Ø§Ù†Ø´' in grade:
                return 'ÙÙ†ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ'
            else:
                return 'Ù…Ø±Ø§Ú©Ø²/Ø³Ø§ÛŒØ±'

        df['Ø¯Ø³ØªÙ‡_Ù…Ù‚Ø·Ø¹'] = df['Ù…Ù‚Ø·Ø¹_ØªØ­ØµÛŒÙ„ÛŒ'].apply(categorize_grade)
        return df
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ù…Ø¯Ø§Ø±Ø³: {e}")
        return pd.DataFrame()

df = load_data()
if df.empty:
    st.warning("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø§Ø² Ù…Ø¯Ø§Ø±Ø³ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯.")
    st.stop()


# --- Û². ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø¬Ø§Ù†Ø¨ÛŒ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ GeoJSON ---

st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙÛŒÙ„ØªØ±")

grade_categories = df['Ø¯Ø³ØªÙ‡_Ù…Ù‚Ø·Ø¹'].unique()
selected_categories = st.sidebar.multiselect(
    "ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡ Ù…Ù‚Ø·Ø¹ ØªØ­ØµÛŒÙ„ÛŒ:",
    options=grade_categories,
    default=grade_categories
)

genders = df['Ø¬Ù†Ø³ÛŒØª'].unique()
selected_genders = st.sidebar.multiselect(
    "ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¬Ù†Ø³ÛŒØª:",
    options=genders,
    default=genders
)

filtered_df = df[
    df['Ø¯Ø³ØªÙ‡_Ù…Ù‚Ø·Ø¹'].isin(selected_categories) &
    df['Ø¬Ù†Ø³ÛŒØª'].isin(selected_genders)
].copy()

# --- Ø¢Ù¾Ù„ÙˆØ¯ GeoJSON Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡) ---
st.sidebar.markdown("---")
st.sidebar.header("ØªØ¹ÛŒÛŒÙ† Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨ (GeoJSON)")
geojson_file_upload = st.sidebar.file_uploader(
    "Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ GeoJSON (Polygon/MultiPolygon)",
    type=["geojson", "json"],
    help="Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø®Øµ Ú©Ø±Ø¯Ù† Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ Ø§Ø² Ø·Ø±ÛŒÙ‚ ÙØ§ÛŒÙ„."
)

if geojson_file_upload:
    try:
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ GeoJSON Ø¯Ø± session state
        st.session_state.uploaded_geojson_data = json.load(geojson_file_upload)
        st.sidebar.success("ÙØ§ÛŒÙ„ GeoJSON Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
    except Exception as e:
        st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ GeoJSON: {e}")
        st.session_state.uploaded_geojson_data = None


# --- Ø¯Ú©Ù…Ù‡ Ø±ÛŒØ³Øª ---
def reset_app():
    """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† GeoJSON Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø±ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ±Ø³ÛŒÙ…Ø§Øª Ø¯Ø³ØªÛŒ."""
    st.session_state.uploaded_geojson_data = None
    st.session_state.reset_trigger += 1 # Ø§ÙØ²Ø§ÛŒØ´ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø±Ù†Ø¯Ø± Ù…Ø¬Ø¯Ø¯ Ù†Ù‚Ø´Ù‡ Ùˆ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ±Ø³ÛŒÙ…Ø§Øª
    # Ø±ÛŒØ³Øª Ú©Ø±Ø¯Ù† Ù…ÙˆÙ‚Ø¹ÛŒØª Ù†Ù‚Ø´Ù‡ Ø¨Ù‡ Ø­Ø§Ù„Øª Ù¾ÛŒØ´ ÙØ±Ø¶ (Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ Ø§ÛŒØ±Ø§Ù†)
    st.session_state.initial_map_location = [32.5, 53.0]
    st.session_state.initial_map_zoom = 5

st.sidebar.markdown("---")
if st.sidebar.button("Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…Ø­Ø¯ÙˆØ¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø±ÛŒØ³Øª Ù†Ù‚Ø´Ù‡"):
    reset_app()
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² st.rerun Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ ØªØºÛŒÛŒØ±Ø§Øª State Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø´Ø±Ø·ÛŒ
    st.rerun()

if filtered_df.empty:
    st.warning("Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙÛŒÙ„ØªØ± ÙØ¹Ù„ÛŒØŒ Ù‡ÛŒÚ† Ù…Ø¯Ø±Ø³Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    st.stop()

st.info(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø¯Ø§Ø±Ø³ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡: **{len(filtered_df)}** Ø§Ø² **{len(df)}**")


# --- Û³. Ø³Ø§Ø®Øª Ù†Ù‚Ø´Ù‡ ÙÙˆÙ„ÛŒÙ… (Folium Map) ---

# Ø³Ø§Ø®Øª Ù†Ù‚Ø´Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± session_state
m = folium.Map(
    location=st.session_state.initial_map_location, 
    zoom_start=st.session_state.initial_map_zoom, 
    tiles="OpenStreetMap"
)

# ØªØ¹Ø±ÛŒÙ Ø±Ù†Ú¯â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡ Ù…Ù‚Ø·Ø¹
category_colors = {
    'Ø§Ø¨ØªØ¯Ø§ÛŒÛŒ/Ø¯Ø¨Ø³ØªØ§Ù†': '#28a745',       # Ø³Ø¨Ø²
    'Ù…ØªÙˆØ³Ø·Ù‡': '#007bff',               # Ø¢Ø¨ÛŒ
    'ÙÙ†ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ': '#ffc107',        # Ø²Ø±Ø¯/Ù†Ø§Ø±Ù†Ø¬ÛŒ
    'Ù…Ø±Ø§Ú©Ø²/Ø³Ø§ÛŒØ±': '#dc3545',           # Ù‚Ø±Ù…Ø² 
}

# --- Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù„Ø§ÛŒÙ‡ Ù…Ø¯Ø§Ø±Ø³ Ø¨Ù‡ Ù†Ù‚Ø´Ù‡ ---
school_layer_group = folium.FeatureGroup(name="Ù†Ù‚Ø§Ø· Ù…Ø¯Ø§Ø±Ø³ (Ø¨Ø± Ø§Ø³Ø§Ø³ ÙÛŒÙ„ØªØ±)", show=True).add_to(m)

for _, row in filtered_df.iterrows():
    lat, lon = row['Ø¹Ø±Ø¶_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], row['Ø·ÙˆÙ„_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
    category = row['Ø¯Ø³ØªÙ‡_Ù…Ù‚Ø·Ø¹']
    
    color = category_colors.get(category, '#6c757d') # Ø±Ù†Ú¯ Ø®Ø§Ú©Ø³ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ
    
    tooltip = (
        f"<b>{row.get('Ù†Ø§Ù…_Ù…Ø¯Ø±Ø³Ù‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')}</b><br>"
        f"Ù…Ù‚Ø·Ø¹: **{row.get('Ù…Ù‚Ø·Ø¹_ØªØ­ØµÛŒÙ„ÛŒ', 'Ù†Ø§Ù…Ø´Ø®Øµ')}**<br>"
        f"Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²: {row.get('ØªØ¹Ø¯Ø§Ø¯_Ø¯Ø§Ù†Ø´_Ø¢Ù…ÙˆØ²', 0)} | Ù…Ø¹Ù„Ù…: {row.get('ØªØ¹Ø¯Ø§Ø¯_Ù…Ø¹Ù„Ù…', 0)}"
    )
    
    folium.CircleMarker(
        location=[lat, lon],
        radius=7,
        color=color,
        fill=True,
        fillColor=color,
        tooltip=folium.Tooltip(tooltip, sticky=True),
    ).add_to(school_layer_group)


# --- Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† GeoJSON Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø¨Ù‡ Ù†Ù‚Ø´Ù‡ ---
uploaded_geojson_data = st.session_state.uploaded_geojson_data
if uploaded_geojson_data:
    folium.GeoJson(
        uploaded_geojson_data,
        name='Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨ (GeoJSON)',
        style_function=lambda x: {
            'fillColor': '#dc3545', 
            'color': '#dc3545',
            'weight': 3, 
            'fillOpacity': 0.3
        },
        tooltip=folium.Tooltip("Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø§Ø² GeoJSON"),
        popup=folium.Popup("Ø§ÛŒÙ† Ù…Ø­Ø¯ÙˆØ¯Ù‡ ØªÙˆØ³Ø· ÙØ§ÛŒÙ„ GeoJSON Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
    ).add_to(m)


# --- Ø§Ø¨Ø²Ø§Ø± ØªØ±Ø³ÛŒÙ… (Draw Plugin) ---
from folium.plugins import Draw
Draw(
    draw_options={
        'polyline':False,
        'rectangle':False,
        'circle':False,
        'marker':False,
        'circlemarker':False,
    }, 
    edit_options={'edit':True, 'remove':True}
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„ÛŒØ¯ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§ reset_trigger Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù¾Ø§Ú© Ø´Ø¯Ù† ØªØ±Ø³ÛŒÙ…Ø§Øª Ù‡Ù†Ú¯Ø§Ù… Ø±ÛŒØ³Øª
).add_to(m)

folium.LayerControl().add_to(m)


# --- Û´. Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ú©Ø§Ù† Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ ---

@st.cache_data(ttl=3600)
def geocode_search(query):
    """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø®ØªØµØ§Øª Ø¨Ø§ Nominatim."""
    try:
        r = requests.get(
            "https://nominatim.openstreetmap.org/search",
            params={'q': query, 'format': 'json', 'limit': 1},
            headers={'User-Agent': 'SchoolDamageAssessmentTool/1.0'}
        ).json()
        if r:
            return float(r[0]["lat"]), float(r[0]["lon"]), r[0]['display_name'].split(',')[0]
        return None, None, None
    except Exception:
        return None, None, None

col1, col2 = st.columns([3,1])
with col1:
    search = st.text_input("Ø¬Ø³ØªØ¬ÙˆÛŒ Ø´Ù‡Ø±/Ù…Ù†Ø·Ù‚Ù‡", placeholder="Ù…Ø«Ù„Ø§Ù‹: Ú¯Ø±Ú¯Ø§Ù†ØŒ ØªÙ‡Ø±Ø§Ù†ØŒ Ù…Ø´Ù‡Ø¯")
with col2:
    st.markdown("<br>", unsafe_allow_html=True)
    # Ø§Ø² on_click Ø¨Ø±Ø§ÛŒ Ø¬Ø§Ø¨Ø¬Ø§ÛŒÛŒ Ù†Ù‚Ø´Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    if st.button("Ø¨Ø±Ùˆ Ø¨Ù‡ Ù…Ú©Ø§Ù†"):
        lat, lon, name = geocode_search(search)
        if lat and lon:
            # Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬Ø¯ÛŒØ¯ Ø¯Ø± session state Ø¨Ø±Ø§ÛŒ ÙÙˆÚ©ÙˆØ³ Ø±ÙˆÛŒ Ù…Ù†Ø·Ù‚Ù‡ Ù…ÙˆØ±Ø¯ Ø¬Ø³ØªØ¬Ùˆ
            st.session_state.initial_map_location = [lat, lon]
            st.session_state.initial_map_zoom = 13
            st.success(f"Ù†Ù‚Ø´Ù‡ Ø¨Ù‡: {name} Ø¬Ø§Ø¨Ø¬Ø§ Ø´Ø¯.")
            st.rerun() 
        else:
            st.error("Ø¬Ø³ØªØ¬Ùˆ Ù†Ø´Ø¯ ÛŒØ§ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù† Ù…Ú©Ø§Ù† ÛŒØ§ÙØª Ù†Ø´Ø¯.")

st.markdown("### Ù†Ù‚Ø´Ù‡ Ù…Ø¯Ø§Ø±Ø³ Ùˆ Ù…Ø­Ø¯ÙˆØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø³ÛŒØ¨")

# Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ùˆ Ø¯Ø±ÛŒØ§ÙØª ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ±Ø³ÛŒÙ… Ø´Ø¯Ù‡
# Ú©Ù„ÛŒØ¯ Ù†Ù‚Ø´Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ ÛŒÚ© Ù…ØªØºÛŒØ± state (Ù…Ø§Ù†Ù†Ø¯ reset_trigger) ØªØ±Ú©ÛŒØ¨ Ø´ÙˆØ¯ ØªØ§ Ø¨Ø§ Ø±ÛŒØ³ØªØŒ Ù†Ù‚Ø´Ù‡ Ùˆ ØªØ±Ø³ÛŒÙ…Ø§Øª Ø¢Ù† Ù¾Ø§Ú© Ø´ÙˆÙ†Ø¯.
map_data = st_folium(m, width=1200, height=600, key=f"folium_map_final_{st.session_state.reset_trigger}")


# --- Ûµ. ØªØ­Ù„ÛŒÙ„ Ù†Ù‚Ø§Ø· Ø¯Ø§Ø®Ù„ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØªØ±Ø³ÛŒÙ… Ø´Ø¯Ù‡ Ùˆ GeoJSON ---

all_shapely_polygons = []
multi_poly = None

# --- Ø§Ù„Ù: Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÛŒ ØªØ±Ø³ÛŒÙ… Ø´Ø¯Ù‡ (Manual Drawings) ---
drawings_exist = False
if map_data and map_data.get("all_drawings"):
    polygons_coords = [
        drawing["geometry"]["coordinates"][0]
        for drawing in map_data["all_drawings"]
        if drawing["geometry"]["type"] == "Polygon"
    ]
    
    if polygons_coords:
        drawings_exist = True
        try:
            # Ø§ÛŒØ¬Ø§Ø¯ Shapely Polygons Ø§Ø² Ù…Ø®ØªØµØ§Øª (Lon, Lat)
            manual_polygons = [Polygon(coords) for coords in polygons_coords]
            all_shapely_polygons.extend(manual_polygons)
        except Exception:
            st.warning("Ø§Ø´Ú©Ø§Ù„ÛŒ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ù†Ø¯Ø³Ù‡ Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯. Ù„Ø·ÙØ§Ù‹ Ø´Ú©Ù„â€ŒÙ‡Ø§ÛŒ ØªØ±Ø³ÛŒÙ…ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")


# --- Ø¨: Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ GeoJSON Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ---
uploaded_geojson_data = st.session_state.uploaded_geojson_data
geojson_exist = False
if uploaded_geojson_data:
    geojson_exist = True
    geojson_data = uploaded_geojson_data
    
    features = []
    if geojson_data.get('type') == 'FeatureCollection':
        features = geojson_data.get('features', [])
    elif geojson_data.get('type') == 'Feature':
        features = [geojson_data]
    elif geojson_data.get('type') in ['Polygon', 'MultiPolygon']:
        features = [{'geometry': geojson_data}]
        
    for feature in features:
        geometry = feature.get('geometry')
        if geometry:
            try:
                geo_obj = shape(geometry)
                
                if geo_obj.geom_type == 'MultiPolygon':
                    for poly in geo_obj.geoms:
                        all_shapely_polygons.append(poly)
                elif geo_obj.geom_type == 'Polygon':
                    all_shapely_polygons.append(geo_obj)
            except Exception as e:
                st.warning(f"Ù‡Ù†Ø¯Ø³Ù‡ GeoJSON Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª ÛŒØ§ Ù‚Ø§Ø¨Ù„ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ³Øª: {e}")
                continue


# --- Ø¬: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ (ØªÙ†Ù‡Ø§ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ù…Ø­Ø¯ÙˆØ¯Ù‡) ---

# Ø´Ø±Ø· Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´: ØªÙ†Ù‡Ø§ Ø§Ú¯Ø± ØªØ±Ø³ÛŒÙ… Ø¯Ø³ØªÛŒ ÛŒØ§ GeoJSON Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡â€ŒØ§ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.
if drawings_exist or geojson_exist:
    
    if all_shapely_polygons:
        try:
            # Ø§Ø¯ØºØ§Ù… ØªÙ…Ø§Ù… Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ†â€ŒÙ‡Ø§ (Ø¯Ø³ØªÛŒ Ùˆ GeoJSON)
            multi_poly = unary_union(all_shapely_polygons)
        except Exception as e:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¯ØºØ§Ù… Ù‡Ù†Ø¯Ø³Ù‡â€ŒÙ‡Ø§: {e}. Ø§Ø´Ú©Ø§Ù„ GeoJSON ÛŒØ§ ØªØ±Ø³ÛŒÙ…ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
            multi_poly = None

    if multi_poly:
        # ØªØ¹ÛŒÛŒÙ† Ù…Ø¯Ø§Ø±Ø³ Ø¯Ø§Ø®Ù„ Ù…Ø­Ø¯ÙˆØ¯Ù‡
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Shapely: Point(Lon, Lat)
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÛŒÚ© Ø³ØªÙˆÙ† Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡
        filtered_df['is_inside'] = filtered_df.apply(
            lambda row: multi_poly.contains(Point(row["Ø·ÙˆÙ„_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ"], row["Ø¹Ø±Ø¶_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ"])),
            axis=1
        )
        
        result = filtered_df[filtered_df['is_inside'] == True].copy()
        
        if not result.empty:
            
            # --- Ú¯Ø²Ø§Ø±Ø´ Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ ---
            total_schools = len(result)
            total_students = result['ØªØ¹Ø¯Ø§Ø¯_Ø¯Ø§Ù†Ø´_Ø¢Ù…ÙˆØ²'].sum()
            total_teachers = result['ØªØ¹Ø¯Ø§Ø¯_Ù…Ø¹Ù„Ù…'].sum()
            
            st.markdown("---")
            st.subheader("Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ")
            
            # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡
            col_metric1, col_metric2, col_metric3 = st.columns(3)
            
            with col_metric1:
                st.metric(
                    label="ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡", 
                    value=total_schools,
                    delta="ğŸš¨ ÙˆØ¶Ø¹ÛŒØª Ø®Ø·Ø±",
                    delta_color="off"
                )
            with col_metric2:
                st.metric(
                    label="Ø¬Ù…Ø¹ Ú©Ù„ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† ØªØ­Øª ØªØ§Ø«ÛŒØ±", 
                    value=total_students
                )
            with col_metric3:
                st.metric(
                    label="Ø¬Ù…Ø¹ Ú©Ù„ Ù…Ø¹Ù„Ù…Ø§Ù† ØªØ­Øª ØªØ§Ø«ÛŒØ±", 
                    value=total_teachers
                )
            
            st.warning("âš ï¸ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§Ù„Ø§ ØµØ±ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‡Ù…Ù¾ÙˆØ´Ø§Ù†ÛŒ Ù…Ú©Ø§Ù†ÛŒ Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ£ÛŒÛŒØ¯ Ù…ÛŒØ¯Ø§Ù†ÛŒ Ø¯Ø§Ø±Ø¯.")
            
            st.markdown("### Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ Ù…Ø­Ø¯ÙˆØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡")

            col_report1, col_report2 = st.columns(2)

            with col_report1:
                st.subheader("ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ø§Ø±Ø³ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ù…Ù‚Ø·Ø¹")
                category_counts = result.groupby('Ø¯Ø³ØªÙ‡_Ù…Ù‚Ø·Ø¹').size().reset_index(name='ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ø§Ø±Ø³')
                category_counts.columns = ['Ø¯Ø³ØªÙ‡ Ù…Ù‚Ø·Ø¹', 'ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ø§Ø±Ø³']
                st.dataframe(category_counts, use_container_width=True, hide_index=True)

            with col_report2:
                st.subheader("ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ø¬Ù†Ø³ÛŒØª")
                gender_student_counts = result.groupby('Ø¬Ù†Ø³ÛŒØª')['ØªØ¹Ø¯Ø§Ø¯_Ø¯Ø§Ù†Ø´_Ø¢Ù…ÙˆØ²'].sum().reset_index(name='ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²')
                gender_student_counts.columns = ['Ø¬Ù†Ø³ÛŒØª', 'ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²']
                st.dataframe(gender_student_counts, use_container_width=True, hide_index=True)
                
            st.markdown("---")
            st.subheader("Ù„ÛŒØ³Øª Ù…Ø¯Ø§Ø±Ø³ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡")
            st.dataframe(
                result[["Ù†Ø§Ù…_Ù…Ø¯Ø±Ø³Ù‡", "Ø¯Ø³ØªÙ‡_Ù…Ù‚Ø·Ø¹", "ØªØ¹Ø¯Ø§Ø¯_Ø¯Ø§Ù†Ø´_Ø¢Ù…ÙˆØ²", "ØªØ¹Ø¯Ø§Ø¯_Ù…Ø¹Ù„Ù…", "Ø¬Ù†Ø³ÛŒØª", "Ø¹Ø±Ø¶_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ", "Ø·ÙˆÙ„_Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ"]],
                width='stretch',
                hide_index=True
            )
            csv = result.to_csv(index=False, encoding="utf-8-sig").encode('utf-8-sig')
            st.download_button(
                "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù„ÛŒØ³Øª (CSV)", 
                csv, 
                "Ù…Ø¯Ø§Ø±Ø³_Ø¢Ø³ÛŒØ¨_Ø¯ÛŒØ¯Ù‡.csv", 
                "text/csv;charset=utf-8-sig"
            )
        else:
            st.warning("Ù‡ÛŒÚ† Ù…Ø¯Ø±Ø³Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ (Ø¯Ø³ØªÛŒ ÛŒØ§ GeoJSON) ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    else:
        st.warning("Ù„Ø·ÙØ§Ù‹ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¢Ø³ÛŒØ¨ Ø±Ø§ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ ØªØ±Ø³ÛŒÙ… Ú©Ù†ÛŒØ¯ ÛŒØ§ ÙØ§ÛŒÙ„ GeoJSON Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ù…Ø§ÛŒÛŒØ¯.")
